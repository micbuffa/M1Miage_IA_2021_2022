{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TD4_skeleton.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fN6CK_ddKlTC"
      },
      "source": [
        "Aujourd'hui, nous allons classer notre ensemble de données en utilisant le Deep Learning."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GdEUOS62Jhl4"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQcAIM6eKuoW"
      },
      "source": [
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn import preprocessing\n",
        "import glob\n",
        "from scipy.io import wavfile\n",
        "from tqdm  import tqdm\n",
        "import pickle\n",
        "from IPython.display import Audio\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "dataset_path = \"/content/drive/My Drive/IA_MIAGE/google-speech-dataset/\"\n",
        "all_classes = os.listdir(dataset_path)\n",
        "all_classes.remove('.git')\n",
        "all_classes.remove('bird') #some outliers in dataset\n",
        "all_classes.remove('_lab_ressources_')\n",
        "all_classes.remove('_background_noise_')\n",
        "chosen_classes = [\"three\", \"tree\"]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4MJ_s-0rKwwH"
      },
      "source": [
        "X_train_waveform = pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/X_train_waveform.pkl\", \"rb\"))\n",
        "X_test_waveform = pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/X_test_waveform.pkl\", \"rb\"))\n",
        "X_val_waveform = pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/X_val_waveform.pkl\", \"rb\"))\n",
        "\n",
        "y_train =  pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/y_train.pkl\", \"rb\"))\n",
        "y_test =  pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/y_test.pkl\", \"rb\"))\n",
        "y_val =  pickle.load(open(\"/content/drive/My Drive/IA_MIAGE/y_val.pkl\", \"rb\"))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9u_iqEOqH5ry"
      },
      "source": [
        "print(X_train_waveform.shape, y_train.shape)\n",
        "print(X_val_waveform.shape, y_val.shape)\n",
        "print(X_test_waveform.shape, y_val.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EosBe3fqLAlX"
      },
      "source": [
        "!pip install sonopy\n",
        "from sonopy import mfcc_spec"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LM1Q-KEPLCZH"
      },
      "source": [
        "def get_mfcc_from_signal(signal):\n",
        "\n",
        "  #extract MFCCs features\n",
        "  single_mfcc = mfcc_spec(signal, 16000, window_stride=(400, 160), fft_size=512, num_filt=20, num_coeffs=13).T\n",
        "\n",
        "  #dropping first coefficient\n",
        "  single_mfcc = single_mfcc[1:,:] #keeping only 12 coefficients\n",
        "\n",
        "  return single_mfcc"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q5xKRrpDLN2X"
      },
      "source": [
        "X_train_mfcc = [get_mfcc_from_signal(signal) for signal in tqdm(X_train_waveform,position=0)]\n",
        "X_val_mfcc = [get_mfcc_from_signal(signal) for signal in tqdm(X_val_waveform,position=0)]\n",
        "X_test_mfcc = [get_mfcc_from_signal(signal) for signal in tqdm(X_test_waveform,position=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Jf77kZXLFBv"
      },
      "source": [
        "X_train_mfcc = np.asarray(X_train_mfcc)\n",
        "X_val_mfcc = np.asarray(X_val_mfcc)\n",
        "X_test_mfcc = np.asarray(X_test_mfcc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WuDp8VnGiXz5"
      },
      "source": [
        "Nous commencerons par CNN (Convolutional Neural Networs). Cet algorithme est conçu pour classer les images. Nous utiliserons ensuite les caractéristiques MFCC de nos pistes comme images."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ll6GFCWiti5"
      },
      "source": [
        "plt.imshow(X_train_mfcc[0], cmap='gray')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "13b_EoCXj-ba"
      },
      "source": [
        "CNN attend comme entrée des tableaux de taille nombre_de_lignes, nombre_de_colonnes, nb_canaux. Nos images n'ont qu'un seul canal."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHiWWNp4K3ZI"
      },
      "source": [
        "'''\n",
        "Adding the channel dimension\n",
        "'''\n",
        "\n",
        "X_train_mfcc_expanded = np.expand_dims(X_train_mfcc, axis=-1)\n",
        "print('train tensor shape:',X_train_mfcc_expanded.shape)\n",
        "\n",
        "X_val_mfcc_expanded = np.expand_dims(X_val_mfcc, axis=-1)\n",
        "print('validation tensor shape:',X_val_mfcc_expanded.shape)\n",
        "\n",
        "X_test_mfcc_expanded = np.expand_dims(X_test_mfcc, axis=-1)\n",
        "print('test tensor shape:',X_test_mfcc_expanded.shape)\n",
        "\n",
        "nb_classes = len(chosen_classes)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQGtpTGNL4Dg"
      },
      "source": [
        "import tensorflow as tf\n",
        "import keras\n",
        "nb_classes = 2\n",
        "y_train = tf.keras.utils.to_categorical(y_train, 2)\n",
        "y_test = tf.keras.utils.to_categorical(y_test, 2)\n",
        "y_val = tf.keras.utils.to_categorical(y_val, 2)\n",
        "\n",
        "print(\"Original class:\", y_test[0], \", Class in one-hot encoding:\", y_test[0])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T2PM2FE8kft6"
      },
      "source": [
        "Comme vous l'avez vu dans le TP précédent, le réseau doit connaître la taille de l'entrée. Nous allons créer ici une couche d'entrée\n",
        "```\n",
        "mfcc = Input(shape=(12,98,1))\n",
        "```\n",
        "Keras fournit également des méthodes pour créer des couches convolutives. \n",
        "\n",
        "```\n",
        "conv_1 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), activation= None, padding='same')\n",
        "```\n",
        "Nous n'entrerons pas dans les détails pour expliquer tous les paramètres d'une couche convolutive, mais pour l'instant il suffit de savoir que  \n",
        "\n",
        "*   filters : Nombre de filtres à apprendre dans la couche\n",
        "*   kernel_size: Taille des filtres\n",
        "\n",
        "La couche *Flatten* convertit une matrice de n dimensions en un tableau de 1 dimension\n",
        "\n",
        "Dans le prochain code, nous ajouterons une couche convolutive suivie de quelques couches *Dense* similaires à celles que nous avons vues dans le dernier TD\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEMiXHw9l98J"
      },
      "source": [
        "from keras.layers import Input, Conv2D, BatchNormalization, Activation, MaxPool2D, Flatten, Dropout, Dense\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras import Model\n",
        "\n",
        "#We first define the input shape\n",
        "mfcc = Input(shape=(12,98,1)) \n",
        "\n",
        "#We build the first convolutional layer and feed it the previously defined Input\n",
        "conv_1 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), padding='same', activation=\"relu\", name=\"conv_1\")(mfcc)\n",
        "\n",
        "# Flattening a tensor means to remove all of the dimensions except for one. This is exactly what the Flatten layer do.\n",
        "# A flatten operation on a tensor reshapes the tensor to have the shape that is equal to the number of elements contained in tensor non including the batch dimension.\n",
        "# See summary bellow to see the change of the shape\n",
        "reshape = Flatten(name=\"flatten\")(conv_1)\n",
        "\n",
        "# dense layer, same as the one used in MLP\n",
        "dense_1 = Dense(128, activation = 'relu', name=\"dense_1\")(reshape)\n",
        "\n",
        "# dropout, sane as the dropout used in MLP\n",
        "dropout = Dropout(rate = 0.2, name=\"dropout\")(dense_1)\n",
        "\n",
        "# dense layer, same as the one used in MLP\n",
        "dense_2 = Dense(128, activation = 'relu', name=\"dense_2\")(dropout)\n",
        "\n",
        "# dense layer, same as the one used in MLP\n",
        "output = Dense(2, activation = 'softmax', name=\"dense_3\")(dense_2)\n",
        "\n",
        "# The line bellow create the model composed by all the layers previously created\n",
        "model = Model(inputs = mfcc, outputs = output)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83pyWSCIm5Ax"
      },
      "source": [
        "Avec la ligne suivante, vous pouvez voir l'architecture de votre réseau"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6pS3faiJnABK"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "STLHMNQPncbS"
      },
      "source": [
        "Le réseau a 4,837,666 paramètres à apprendre.\n",
        "\n",
        "Une technique pour réduire la taille de l'image après la convolution consiste à utiliser une couche *Pooling*. Comme le montre le gif suivant, il divise l'image en grilles et extrait le maximum de chaque grille.\n",
        "\n",
        "<img src=\"https://developers.google.com/machine-learning/practica/image-classification/images/maxpool_animation.gif\" width=\"500\"/>\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3GpmVF37s2q1"
      },
      "source": [
        "mfcc = Input(shape=(12,98,1)) \n",
        "\n",
        "conv_1 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), padding='same', activation=\"relu\", name=\"conv_1\")(mfcc)\n",
        "\n",
        "max_pool = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "reshape = Flatten(name=\"flatten\")(max_pool)\n",
        "\n",
        "dense_1 = Dense(128, activation = 'relu', name=\"dense_1\")(reshape)\n",
        "\n",
        "dropout = Dropout(rate = 0.2, name=\"dropout\")(dense_1)\n",
        "\n",
        "output = Dense(2, activation = 'softmax', name=\"dense_2\")(dropout)\n",
        "\n",
        "model = Model(inputs = mfcc, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ScksmVBttMyZ"
      },
      "source": [
        "En ajoutant une couche MaxPool après la couche convolutionnelle, nous avons réduit la taille de l'image de (12, 98, 32) à (6, 49, 32) et le nombre de paramètres à apprendre de 4 837 666 à 1 224 994.\n",
        "\n",
        "\n",
        "Maintenant, entraînons notre petit modèle"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_jTXuyWotoUB"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.003),metrics=['accuracy'])\n",
        "\n",
        "print(\"Training ...\")\n",
        "\n",
        "history_cnn = model.fit(X_train_mfcc_expanded,y_train,validation_data = (X_val_mfcc_expanded, y_val),batch_size=64, epochs=5, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3YLaOydVv7JT"
      },
      "source": [
        "print(\"Testing ...\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_mfcc_expanded, y_test,verbose = 1)\n",
        "\n",
        "print('model accuracy:',accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ARon3SkDvnVR"
      },
      "source": [
        "Vous pouvez également ajouter d'autres couches convolutives, l'une après l'autre. (N'oubliez pas que l'ajout de couches n'est pas toujours une bonne solution.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeVduBWRvz4K"
      },
      "source": [
        "mfcc = Input(shape=(12,98,1)) \n",
        "\n",
        "conv_1 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), padding='same', activation=\"relu\", name=\"conv_1\")(mfcc)\n",
        "\n",
        "max_pool = MaxPool2D(pool_size=(2, 2))(conv_1)\n",
        "\n",
        "dropout_1 = Dropout(rate = 0.2, name=\"dropout_1\")(max_pool)\n",
        "\n",
        "conv_2 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), padding='same', activation=\"relu\", name=\"conv_2\")(dropout_1)\n",
        "\n",
        "reshape = Flatten(name=\"flatten\")(conv_2)\n",
        "\n",
        "dense_1 = Dense(128, activation = 'relu', name=\"dense_1\")(reshape)\n",
        "\n",
        "dropout_2 = Dropout(rate = 0.2, name=\"dropout_2\")(dense_1)\n",
        "\n",
        "output = Dense(2, activation = 'softmax', name=\"dense_2\")(dropout_2)\n",
        "\n",
        "model = Model(inputs = mfcc, outputs = output)\n",
        "\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u-RzpR8IwpRJ"
      },
      "source": [
        "model.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.003),metrics=['accuracy'])\n",
        "\n",
        "print(\"Training ...\")\n",
        "\n",
        "history_cnn = model.fit(X_train_mfcc_expanded,y_train,validation_data = (X_val_mfcc_expanded, y_val),batch_size=64, epochs=5, shuffle=True)\n",
        "\n",
        "print(\"Testing ...\")\n",
        "\n",
        "loss, accuracy = model.evaluate(X_test_mfcc_expanded, y_test,verbose = 1)\n",
        "\n",
        "print('model accuracy:',accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6iBTdQRVyW-L"
      },
      "source": [
        "Créons un modèle plus complexe pour évaluer les autres techniques que nous avons vues pendant le cours."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Cnw61xyaLlWh"
      },
      "source": [
        "def CNN():\n",
        "\n",
        "  mfcc = Input(shape=(12,98,1)) \n",
        "\n",
        "  conv_1 = Conv2D(filters=32, kernel_size=(8,15), strides=(1,1), activation= None, padding='same')(mfcc)\n",
        "  norm_1 = BatchNormalization()(conv_1)\n",
        "  activ_1 = Activation('relu')(norm_1)\n",
        "\n",
        "  dropout_1 = Dropout(rate=0.1)(activ_1)\n",
        "\n",
        "  max_pool = MaxPool2D(pool_size=(2, 2))(dropout_1)\n",
        "\n",
        "  conv_2 = Conv2D(filters=32, kernel_size=(4,10),strides=(1,1), activation= None,padding='same')(max_pool)\n",
        "  norm_2 = BatchNormalization()(conv_2)\n",
        "  activ_2 = Activation('relu')(norm_2)\n",
        "\n",
        "  dropout_2 = Dropout(rate=0.1)(activ_2)\n",
        "\n",
        "  reshape = Flatten()(dropout_2)\n",
        "\n",
        "  dense_1 = Dense(128, activation = 'relu')(reshape)\n",
        "  dropout_3 = Dropout(rate = 0.2)(dense_1)\n",
        "  dense_2 = Dense(128, activation = 'relu')(dropout_3)\n",
        "  output = Dense(2, activation = 'softmax')(dense_2)\n",
        "\n",
        "  modell = Model(inputs = mfcc, outputs = output)\n",
        "\n",
        "  return modell\n",
        "\n",
        "model_cnn = CNN()\n",
        "\n",
        "model_cnn.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.003),metrics=['accuracy'])\n",
        "\n",
        "model_cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AREncVNILqGQ"
      },
      "source": [
        "print(\"Training ...\")\n",
        "history_cnn = model_cnn.fit(X_train_mfcc_expanded,y_train,validation_data = (X_val_mfcc_expanded, y_val),batch_size=32, epochs=8, shuffle=True)\n",
        "\n",
        "print(\"Testing ...\")\n",
        "\n",
        "loss, accuracy = model_cnn.evaluate(X_test_mfcc_expanded, y_test,verbose = 1)\n",
        "\n",
        "print('model accuracy:',accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U0fSd74W1jFB"
      },
      "source": [
        "Avec la fonction suivante, vous pouvez tracer la précision de training et validation."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4_c7QiUpMVUY"
      },
      "source": [
        "def plot_history(history):\n",
        "  plt.plot(history.history['accuracy'])\n",
        "  plt.plot(history.history['val_accuracy'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'val'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "plot_history(history_cnn)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROzp39LF4GSR"
      },
      "source": [
        "LSTM est un algorithme d'apprentissage automatique très utile pour les séquences temporelles comme les échantillons audio."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5G5KORcGwFyu"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0k-QWPJlMv5f"
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Bidirectional, LSTM, Dropout\n",
        "\n",
        "model_lstm = Sequential()\n",
        "model_lstm.add(LSTM(32,input_shape=(98,12)))\n",
        "model_lstm.add(Dropout(0.2))\n",
        "model_lstm.add(Dense(2,activation='softmax'))\n",
        "\n",
        "model_lstm.compile(optimizer=\"adam\",loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "\n",
        "model_lstm.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WuS8TlwfM2Zn"
      },
      "source": [
        "print(\"Training ...\")\n",
        "history_lstm = model_lstm.fit(np.transpose(X_train_mfcc, (0,2,1)),y_train,validation_data = (np.transpose(X_val_mfcc, (0,2,1)), y_val),batch_size=32, epochs=30, shuffle=True)\n",
        "\n",
        "print(\"Testing ...\")\n",
        "loss, accuracy = model_lstm.evaluate(np.transpose(X_test_mfcc, (0,2,1)), y_test,verbose = 1)\n",
        "\n",
        "print('model accuracy:',accuracy)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ADIHHYUkM99x"
      },
      "source": [
        "plot_history(history_lstm)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W73P-_ge6QB6"
      },
      "source": [
        "Nos résultats précédents sont assez bons ; cependant, ce que nous avons fait auparavant n'est que des exemples de jouets. Maintenant, nous allons compliquer le problème pour qu'il soit plus proche des cas d'utilisation réelle :\n",
        "\n",
        "Nous allons ajouter du bruit à nos échantillons audio car nous voulons que notre modèle fonctionne dans un environnement potentiellement bruyant. Ce processus est appelé \"augmentation des données\" : dans le scénario du monde réel, nous pouvons avoir un ensemble de données audio prises dans un ensemble limité de conditions. Mais notre application cible peut exister dans une variété de conditions. Nous voulons donner au réseau la possibilité d'ignorer le bruit.\n",
        "\n",
        "Nous allons maintenant mélanger un signal avec du bruit et comprendre le concept de SNR.\n",
        "\n",
        "Dans le dataset que vous avez téléchargé dans le premier TD, il y a quelques échantillons de bruit.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HgZX1EhNRoin"
      },
      "source": [
        "def normalize(audio_signal):\n",
        "  audio_signal = np.array(audio_signal) ##Audio signal as array, in case it's not\n",
        "  max_value = max(np.absolute(audio_signal)) ## Get the maximum positive value\n",
        "  norm_signal = audio_signal / max_value\n",
        "  return norm_signal\n",
        "\n",
        "def add_padding(audio_signal, desired_len):\n",
        "  \n",
        "  length_signal = len(audio_signal)\n",
        "  if length_signal < desired_len:\n",
        "    zeros = np.zeros(desired_len)\n",
        "    start_signal = random.randint(0, desired_len - length_signal) ## Bonne Question: Pourquoi aléatoire?\n",
        "    zeros[start_signal: start_signal + length_signal] = audio_signal\n",
        "    return zeros\n",
        "    \n",
        "  return audio_signal\n",
        "\n",
        "def get_signal(signal_path):\n",
        "  \n",
        "  rate, sig = wavfile.read(filename=signal_path)\n",
        "  \n",
        "  try:\n",
        "    sig = sig[:, 0]\n",
        "  except:\n",
        "    pass\n",
        "  \n",
        "  #normalization\n",
        "  sig = normalize(sig)\n",
        "\n",
        "  #standardization of sizes\n",
        "  sig = add_padding(sig,16000)\n",
        "  \n",
        "  return sig"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2s0zbOY47N0r"
      },
      "source": [
        "noise_path = glob.glob(dataset_path + '_background_noise_/*wav')\n",
        "\n",
        "noise_lib = [get_signal(p) for p in tqdm(noise_path, position=0)]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OWCARN6V7U3Q"
      },
      "source": [
        "Voyons le graphique et écoutons le son de certains des signaux de bruit."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-0qtP9Sn7ies"
      },
      "source": [
        "noise = random.choice(noise_path)\n",
        "noise_wav = get_signal(noise)\n",
        "\n",
        "plt.figure()\n",
        "n_name = noise.split('/')[-1].split('.wav')[0]\n",
        "cut = random.randint(0, len(noise_wav))\n",
        "plt.plot(noise_wav[cut:cut+16000])\n",
        "plt.title(f\"Noise waveform: {n_name}\")\n",
        "plt.show()\n",
        "\n",
        "Audio(noise_wav, rate=16000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJiSovqw9L6K"
      },
      "source": [
        "**SNR** (Signal to Noise Ratio) ou Rapport signal sur bruit\n",
        "\n",
        "À ce stade, avant le mixage, nous avons besoin d'un moyen de mesurer la quantité de bruit à ajouter au signal original. Nous voulons contrôler l'intensité sonore et le signal bruyant pour comprendre comment les performances de la classification évoluent pour différents niveaux de bruit. \n",
        "\n",
        "La mesure utilisée pour contrôler le niveau de bruit à ajouter ou à retirer du signal est le **(SNR)**. Il s'agit d'une mesure utilisée en science et en ingénierie qui compare le niveau d'un signal souhaité au niveau du bruit de fond. Le SNR est défini comme le rapport entre la puissance du signal et la puissance du bruit, souvent exprimé en décibels. Un rapport supérieur à 1:1 (supérieur à 0 dB) indique qu'il y a plus de signal que de bruit. Le rapport signal/bruit est défini comme le rapport entre la puissance d'un signal (information significative) et la puissance du bruit de fond (signal indésirable) :\n",
        "\n",
        "$SNR = \\frac{P_{signal}}{S_{noise}}$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VMm0uM_ZOq3w"
      },
      "source": [
        "## Fonctions permettant d'ajouter du bruit aux signaux originaux\n",
        "\n",
        "def cal_adjusted_rms(clean_rms, snr):\n",
        "    a = float(snr) / 20\n",
        "    noise_rms = clean_rms / (10 ** a)\n",
        "    return noise_rms\n",
        "  \n",
        "\n",
        "def cal_rms(amp):\n",
        "    return np.sqrt(np.mean(np.square(amp), axis=-1))\n",
        "\n",
        "def add_noise(signal, noise, snr):\n",
        "    '''\n",
        "    signal: np.ndarray\n",
        "    snr: signed integer\n",
        "\n",
        "    returns -> np.ndarray\n",
        "    '''\n",
        "\n",
        "    index = random.randint(0, len(noise) - len(signal))\n",
        "    noise = noise[index:index+len(signal)]\n",
        "\n",
        "    clean_rms = cal_rms(signal)\n",
        "\n",
        "    # take part of noise and:\n",
        "    noise_rms = cal_rms(noise)\n",
        "\n",
        "    #noise amplitude\n",
        "    adjusted_noise_rms = cal_adjusted_rms(clean_rms, snr)\n",
        "\n",
        "    adjusted_noise_amp = noise * (adjusted_noise_rms / noise_rms)\n",
        "    mixed_amp = (signal + adjusted_noise_amp)\n",
        "\n",
        "    max_int16 = np.iinfo(np.int16).max\n",
        "    if mixed_amp.max(axis=0) > max_int16:\n",
        "        reduction_rate = max_int16 / mixed_amp.max(axis=0)\n",
        "        mixed_amp = mixed_amp * (reduction_rate)\n",
        "\n",
        "    return mixed_amp/ max(np.absolute(mixed_amp))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQfV9kuL-a0r"
      },
      "source": [
        "Essayez maintenant de mélanger les deux sons à des niveaux de SNR différents en changeant la valeur **snr** ci-dessous. N'oubliez pas que plus cette valeur est basse, plus le mélange sera bruyant. Vous pouvez également jouer le son pour avoir un retour direct. (N'oubliez pas de ré-exécuter la cellule à chaque fois que vous changez le snr.)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sGnCLhM9QxBk"
      },
      "source": [
        "snr = -5 ## A completer. \n",
        "signal = X_train_waveform[0]\n",
        "mixed = add_noise(signal, noise_wav, snr)\n",
        "\n",
        "#waveform noise\n",
        "plt.figure()\n",
        "plt.subplot(221)\n",
        "plt.plot(signal)\n",
        "plt.title(f\"Signal\")\n",
        "plt.subplot(222)\n",
        "plt.plot(mixed)\n",
        "plt.title(f\"Signal and noise mixed at {snr} SNR\")\n",
        "plt.show()\n",
        "mixed = (mixed*32767).astype(np.int16) \n",
        "wavfile.write(dataset_path + '/mixed.wav', 16000, mixed)\n",
        "Audio(dataset_path + '/mixed.wav')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjj8EE9-_sDU"
      },
      "source": [
        "En gardant cela à l'esprit, nous pouvons augmenter notre ensemble de données et essayer de rendre notre modèle plus robuste au bruit. Pour ce faire, nous sélectionnons au hasard un fichier de bruit dans notre ensemble de données et le mélangeons à l'un des fichiers de l'ensemble de données à un niveau aléatoire de SNR compris entre -5 et +20. \n",
        "\n",
        "Cela signifie que notre ensemble de données augmenté aura deux fois plus de fichiers audio que la version propre.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5dYuPXV8Q05_"
      },
      "source": [
        "snr = np.arange(-5,+20)\n",
        "def augment_data(signal, snr_range=snr):\n",
        "\n",
        "  noise = random.choice(noise_lib)\n",
        "  snr = random.choice(snr_range)\n",
        "    \n",
        "  mixed = add_noise(signal, noise, snr)\n",
        "    \n",
        "  return mixed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIoxpEn_Q6EI"
      },
      "source": [
        "'''\n",
        "adding noise\n",
        "'''\n",
        "X_train_aug = [augment_data(signal) for signal in tqdm(X_train_waveform,position=0)]\n",
        "X_test_aug = [augment_data(signal) for signal in tqdm(X_test_waveform,position=0)]\n",
        "X_val_aug = [augment_data(signal) for signal in tqdm(X_val_waveform,position=0)]\n",
        "\n",
        "'''\n",
        "'get mfcc features'\n",
        "'''\n",
        "X_train_noisy_mfcc = np.asarray([get_mfcc_from_signal(signal) for signal in tqdm(X_train_aug,position=0)])\n",
        "X_test_noisy_mfcc = np.asarray([get_mfcc_from_signal(signal) for signal in tqdm(X_test_aug,position=0)])\n",
        "X_val_noisy_mfcc = np.asarray([get_mfcc_from_signal(signal) for signal in tqdm(X_val_aug,position=0)])\n",
        "\n",
        "'''\n",
        "get augmented dataset with clean and noisy data\n",
        "'''\n",
        "X_train_noisy = np.concatenate((X_train_noisy_mfcc, X_train_mfcc), axis=0)\n",
        "X_test_noisy = np.concatenate((X_test_noisy_mfcc, X_test_mfcc), axis=0)\n",
        "X_val_noisy = np.concatenate((X_val_noisy_mfcc, X_val_mfcc), axis=0)\n",
        "\n",
        "\n",
        "print('X_train_noisy:',len(X_train_noisy))\n",
        "print('X_val_noisy:',len(X_val_noisy))\n",
        "print('X_test_noisy:',len(X_test_noisy))\n",
        "\n",
        "\n",
        "'''\n",
        "labels\n",
        "'''\n",
        "y_train_noisy = np.array(list(y_train) + list(y_train))\n",
        "y_val_noisy = np.array(list(y_val) + list(y_val))\n",
        "\n",
        "\n",
        "print(\"y_train_noisy:\",len(y_train_noisy))\n",
        "print(\"y_val_noisy:\",len(y_val_noisy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDOIDfPIAIqq"
      },
      "source": [
        "La fonction suivante vous permet d'évaluer un modèle dans une gamme de valeurs snr."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PXEnynb6SXLo"
      },
      "source": [
        "def accuracy_by_SNR(MODEL, TEST_WAVEFORMS = X_test_waveform, LABELS = y_test,MIN_SNR=-15,MAX_SNR=30,SNR_STEP=5):\n",
        "  \n",
        "  SNRs = list(range(MIN_SNR,MAX_SNR+1,)[0::SNR_STEP])\n",
        "  \n",
        "  ###\n",
        "  acc = []\n",
        "  for SNR in SNRs:\n",
        "    \n",
        "    X_noisy_SNR = []\n",
        "    \n",
        "    for SIGNAL in TEST_WAVEFORMS:\n",
        "      \n",
        "      NOISE = random.choice(noise_lib)\n",
        "      X_noisy_SNR.append(add_noise(SIGNAL, NOISE, SNR))\n",
        "    \n",
        "    X_noisy_SNR_mfcc = [get_mfcc_from_signal(signal) for signal in tqdm(X_noisy_SNR,position=0)]\n",
        "    X_noisy_SNR_mfcc_expanded = np.expand_dims(X_noisy_SNR_mfcc, axis=-1)  \n",
        "    \n",
        "  \n",
        "    loss, accuracy = MODEL.evaluate(X_noisy_SNR_mfcc_expanded, y_test,verbose=0)\n",
        "    \n",
        "    print('SNR:',SNR,\" - acc: \", accuracy)\n",
        "    acc.append(accuracy)\n",
        "    \n",
        "  return acc, SNRs  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N6-hrcIiAqDU"
      },
      "source": [
        "Rappelez-vous que nous avons entraîné un modèle CNN avec notre ensemble de données (contenant uniquement les échantillons propres). Évaluons ce modèle avec ces nouveaux échantillons bruyants. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rfA5BkogASxB"
      },
      "source": [
        "acc_without_DA, snrs = accuracy_by_SNR(model_cnn)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(snrs,acc_without_DA,color='blue')\n",
        "plt.title(\"Accuracy according to the SNR\")\n",
        "plt.xlabel(\"SNR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atKWfa5mA_VB"
      },
      "source": [
        "Maintenant, entraînons dès le début une nouvelle CNN avec la même structure que celle vue précédemment, mais en utilisant les données augmentées. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jY_g-O0_TPbA"
      },
      "source": [
        "model_cnn_noisy = CNN()\n",
        "model_cnn_noisy.compile(loss='categorical_crossentropy',\n",
        "              optimizer = Adam(lr=0.003),metrics=['accuracy'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xQtrh_P3TZ5v"
      },
      "source": [
        "X_train_noisy_expanded = np.expand_dims(X_train_noisy, axis=-1)\n",
        "X_val_noisy_expanded = np.expand_dims(X_val_noisy, axis=-1)\n",
        "\n",
        "print(\"Training ...\")\n",
        "history_cnn_noisy = model_cnn_noisy.fit(X_train_noisy_expanded,y_train_noisy,validation_data = (X_val_noisy_expanded, y_val_noisy),batch_size=64, epochs=10, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "typeWy36BzbJ"
      },
      "source": [
        "acc_with_DA, snrs = accuracy_by_SNR(model_cnn_noisy)\n",
        "\n",
        "plt.figure(figsize=(10,7))\n",
        "plt.plot(snrs,acc_without_DA)\n",
        "plt.plot(snrs,acc_with_DA)\n",
        "plt.title(\"Accuracy according to the SNR\")\n",
        "plt.xlabel(\"SNR\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.legend(['without data augmentation', 'with data augmentation'], loc='lower right')\n",
        "\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n-VZlhLeB9tN"
      },
      "source": [
        "Vous pouvez faire le même test avec le modèle LSTM...."
      ]
    }
  ]
}